---
layout: page
---

# About Me

<img src="images/profile2.jpg" class="floatpic" width="360" height="480">

Here is **Hanyang Zhong (Hanyang, 钟翰扬)**.

I am a second-year PhD candidate in the School of Electronic Engineering at the University of York in the UK. My research interests encompass large language models, multi-modality, trustworthy AI, computer vision, and robotics. I am currently conducting doctoral research under the supervision of Professor Mark Post, investigating the integration of large language models with underwater robots. Additionally, I was recently selected to serve as a Reviewer for the IEEE International Conference on Multimedia and Expo **(ICME)**. 

My background includes experience as a researcher in Professor Post's lab at York, where my focus has been on advancing the state-of-the-art in language model capabilities for robotic platforms. I have a passion for interdisciplinary research that bridges AI, robotics, and multimedia modalities. 

I would be delighted to discuss potential collaborations or my research in more detail. Please feel free to email me if you would like to connect further (hanyangzhong@york.ac.uk).

---

## Academic Background

**<font color='red'>[Highlight]</font> I am looking for postdoctoral research to start in 2025 Fall. Contact me if you have any leads!**

- **Sep 2015 - June 2019:** Nanchang Institute of Technology (BEng)
- **Sep 2021 - June 2022:** University of York (MSc)
- **Sep 2022 - Now:** University of York (Phd)

I am currently pursuing a PhD. Upon successful PhD completion, I hope to obtain postdoctoral research opportunities in academia or industry. My goal is to excel in my doctoral studies to be competitive for quality postdoc positions related to my expertise.

<br>

---

## Research Interests

- Large language models (LLM)
- Multi-modality
- Trustworthy AI
- AI Agent
- Robotics
- Embodied AI


My research centers on advancing **Embodied AI** by integrating large language models with **Robotic** platforms, investigating how a robot's grounded **Multi-modality** experiences may enrich and enhance the knowledge and inferences of a language model.

<br>

---

## News and Updates

- **Jan 2024:** Becoming an **ICME reviewer**!
- **Dec 2023:** I recently posted a preprint on arXiv titled "**[LLM-SAP: Large Language Model Situational Awareness Based Planning]**(https://github.com/HanyangZhong/Situational_Planning_datasets)" exploring the use of LLMs to enable context-aware robot planning. I welcome constructive feedback, related perspectives, and relevant citations from the community as I continue developing these ideas at the intersection of language models, robotics, and embodied intelligence. Please reach out if you see potential connections to your own research - I believe open collaboration can advance this emerging field.
- **Dec 2023:** I recently posted the preprint "**[FENet: Focusing Enhanced Network for Lane Detection]**(https://github.com/HanyangZhong/FENet)" on arXiv. This paper proposes a novel neural network approach to improve lane detection capabilities in autonomous driving. I welcome constructive feedback, relevant perspectives, and citations from the community as I continue refining this method. Please reach out if you see potential connections to your own work at the intersection of computer vision and autonomous systems - open collaboration can advance this important field.


<br>
